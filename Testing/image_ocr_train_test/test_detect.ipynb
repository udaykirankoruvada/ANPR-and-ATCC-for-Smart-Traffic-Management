{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-05T14:03:06.767982Z",
     "start_time": "2024-12-05T14:02:56.843055Z"
    }
   },
   "source": [
    "data_dir = '.'\n",
    "\n",
    "import os\n",
    "import math\n",
    "import imgaug\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "\n",
    "import image_ocr"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# dataset\n",
   "id": "a2ca4e3709456f5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train, validation = sklearn.model_selection.train_test_split(\n",
    "    dataset, train_size=0.8, random_state=42\n",
    ")\n",
    "augmenter = imgaug.augmenters.Sequential([\n",
    "    imgaug.augmenters.Affine(\n",
    "      scale=(1.0, 1.2),\n",
    "      rotate=(-5, 5)\n",
    "    ),\n",
    "    imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),\n",
    "    imgaug.augmenters.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "])\n",
    "generator_kwargs = {'width': 640, 'height': 640}\n",
    "training_image_generator = image_ocr.datasets.get_detector_image_generator(\n",
    "    labels=train,\n",
    "    augmenter=augmenter,\n",
    "    **generator_kwargs\n",
    ")\n",
    "validation_image_generator = image_ocr.datasets.get_detector_image_generator(\n",
    "    labels=validation,\n",
    "    **generator_kwargs\n",
    ")\n",
    "\n",
    "# Display an example\n",
    "image, lines, confidence = next(training_image_generator)\n",
    "canvas = image_ocr.tools.drawBoxes(image=image, boxes=lines, boxes_format='lines')\n",
    "plt.imshow(canvas)"
   ],
   "id": "1f17bc3d3a93bea1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initalized with default weights\n",
    "detector = image_ocr.detection.Detector()"
   ],
   "id": "6bbf561e2891c797"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 1\n",
    "training_generator, validation_generator = [\n",
    "    detector.get_batch_generator(\n",
    "        image_generator=image_generator, batch_size=batch_size\n",
    "    ) for image_generator in\n",
    "    [training_image_generator, validation_image_generator]\n",
    "]"
   ],
   "id": "d3fb89da7e5e2f5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "detector.model.fit(\n",
    "    training_generator,\n",
    "    steps_per_epoch=math.ceil(len(train) / batch_size),\n",
    "    epochs=1000,\n",
    "    workers=0,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5),\n",
    "        tf.keras.callbacks.CSVLogger(os.path.join(data_dir, 'detector_icdar2013.csv')),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(data_dir, 'detector_icdar2013.h5'))\n",
    "    ],\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=math.ceil(len(validation) / batch_size)\n",
    ")"
   ],
   "id": "901ef4e2d5887b24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## code of chatgpt after edits\n",
   "id": "a38e24f761ad88d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:38:26.744747Z",
     "start_time": "2024-12-05T15:38:26.714649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import math\n",
    "import imgaug\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import image_ocr"
   ],
   "id": "6c8035ccff63b93e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:38:20.947062Z",
     "start_time": "2024-12-05T15:38:20.937511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# if physical_devices:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#         print(\"GPU is available and ready!\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)"
   ],
   "id": "1e7ec29b0148cff1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:43:12.263037Z",
     "start_time": "2024-12-05T15:43:12.231774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Custom Dataset\n",
    "class CustomDataset:\n",
    "    def __init__(self, image_dir, annotations_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def parse_annotation(self, annotation_file):\n",
    "        tree = ET.parse(annotation_file)\n",
    "        root = tree.getroot()\n",
    "        lines = []\n",
    "\n",
    "        for obj in root.findall('object'):\n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = int(bbox.find('xmin').text)\n",
    "            ymin = int(bbox.find('ymin').text)\n",
    "            xmax = int(bbox.find('xmax').text)\n",
    "            ymax = int(bbox.find('ymax').text)\n",
    "            lines.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        return lines\n",
    "\n",
    "    def load_data(self):\n",
    "        dataset = []\n",
    "        for img_file in self.image_files:\n",
    "            img_path = os.path.join(self.image_dir, img_file)\n",
    "            annotation_path = os.path.join(self.annotations_dir, os.path.splitext(img_file)[0] + '.xml')\n",
    "            if os.path.exists(annotation_path):\n",
    "                boxes = self.parse_annotation(annotation_path)\n",
    "                # Adding dummy confidence scores for each box\n",
    "                confidence = [1.0] * len(boxes)  # Assuming a confidence of 1.0 for all annotations\n",
    "                dataset.append((img_path, boxes, confidence))\n",
    "        return dataset\n",
    "\n"
   ],
   "id": "62991af4c19ecfa8",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:43:15.004409Z",
     "start_time": "2024-12-05T15:43:13.988234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define paths\n",
    "image_dir = \"F://Udaykiran//silent//ANPR-and-ATCC-for-Smart-Traffic-Management//dataset//indian_license_dataset//images\"\n",
    "annotations_dir = \"F://Udaykiran//silent//ANPR-and-ATCC-for-Smart-Traffic-Management//dataset//indian_license_dataset//annote\"\n",
    "# Load dataset\n",
    "custom_dataset = CustomDataset(image_dir, annotations_dir)\n",
    "dataset = custom_dataset.load_data()\n",
    "\n",
    "# Split data\n",
    "train, validation = sklearn.model_selection.train_test_split(dataset, train_size=0.8, random_state=42)\n"
   ],
   "id": "cc1752e02d50a8e2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:43:16.713702Z",
     "start_time": "2024-12-05T15:43:16.681775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Augmentations\n",
    "augmenter = imgaug.augmenters.Sequential([\n",
    "    imgaug.augmenters.Affine(scale=(1.0, 1.2), rotate=(-5, 5)),\n",
    "    imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),\n",
    "    imgaug.augmenters.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "])\n",
    "\n",
    "# Generator arguments\n",
    "generator_kwargs = {'width': 640, 'height': 640}\n",
    "\n",
    "# Training and validation generators\n",
    "training_image_generator = image_ocr.datasets.get_detector_image_generator(\n",
    "    labels=train,\n",
    "    augmenter=augmenter,\n",
    "    **generator_kwargs\n",
    ")\n",
    "validation_image_generator = image_ocr.datasets.get_detector_image_generator(\n",
    "    labels=validation,\n",
    "    **generator_kwargs\n",
    ")\n"
   ],
   "id": "16e4b256ed280ff8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "bdac409611f04ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:43:19.201964Z",
     "start_time": "2024-12-05T15:43:18.309015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display an example\n",
    "image, lines, confidence = next(training_image_generator)\n",
    "canvas = image_ocr.tools.drawBoxes(image=image, boxes=lines, boxes_format='lines')\n",
    "plt.imshow(canvas)\n",
    "plt.show()\n",
    "\n",
    "# Initialize Detector\n",
    "detector = image_ocr.detection.Detector()\n",
    "\n",
    "# Batch size\n",
    "batch_size = 1\n",
    "\n",
    "# Batch Generators\n",
    "training_generator, validation_generator = [\n",
    "    detector.get_batch_generator(\n",
    "        image_generator=image_generator, batch_size=batch_size\n",
    "    ) for image_generator in [training_image_generator, validation_image_generator]\n",
    "]\n",
    "\n",
    "# Model Training\n",
    "detector.model.fit(\n",
    "    training_generator,\n",
    "    steps_per_epoch=math.ceil(len(train) / batch_size),\n",
    "    epochs=1000,\n",
    "    workers=0,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5),\n",
    "        tf.keras.callbacks.CSVLogger(os.path.join('.', 'detector_training.csv')),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join('.', 'detector_best_model.h5'))\n",
    "    ],\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=math.ceil(len(validation) / batch_size)\n",
    ")"
   ],
   "id": "2655d8bfd9d168a1",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Display an example\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m image, lines, confidence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtraining_image_generator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m canvas \u001B[38;5;241m=\u001B[39m image_ocr\u001B[38;5;241m.\u001B[39mtools\u001B[38;5;241m.\u001B[39mdrawBoxes(image\u001B[38;5;241m=\u001B[39mimage, boxes\u001B[38;5;241m=\u001B[39mlines, boxes_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(canvas)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\image_ocr\\datasets.py:385\u001B[0m, in \u001B[0;36mget_detector_image_generator\u001B[1;34m(labels, width, height, augmenter, area_threshold, focused, min_area, shuffle)\u001B[0m\n\u001B[0;32m    383\u001B[0m image \u001B[38;5;241m=\u001B[39m tools\u001B[38;5;241m.\u001B[39mread(image_filepath)\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m augmenter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 385\u001B[0m     image, lines \u001B[38;5;241m=\u001B[39m \u001B[43mtools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maugment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mboxes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mboxes_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlines\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43marea_threshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marea_threshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_area\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmin_area\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[43maugmenter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maugmenter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m focused:\n\u001B[0;32m    394\u001B[0m     boxes \u001B[38;5;241m=\u001B[39m [tools\u001B[38;5;241m.\u001B[39mcombine_line(line)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\image_ocr\\tools.py:327\u001B[0m, in \u001B[0;36maugment\u001B[1;34m(boxes, augmenter, image, boxes_format, image_shape, area_threshold, min_area)\u001B[0m\n\u001B[0;32m    319\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    320\u001B[0m         box\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m inside, box \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    324\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m inside\n\u001B[0;32m    325\u001B[0m     ]\n\u001B[0;32m    326\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m boxes_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 327\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    328\u001B[0m         [(augment_box(box), character) \u001B[38;5;28;01mfor\u001B[39;00m box, character \u001B[38;5;129;01min\u001B[39;00m line] \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m boxes\n\u001B[0;32m    329\u001B[0m     ]\n\u001B[0;32m    330\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    331\u001B[0m         [\n\u001B[0;32m    332\u001B[0m             (box, character)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    338\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m boxes_augmented\n\u001B[0;32m    339\u001B[0m     ]\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;66;03m# Sometimes all the characters in a line are removed.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\image_ocr\\tools.py:328\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    319\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    320\u001B[0m         box\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m inside, box \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    324\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m inside\n\u001B[0;32m    325\u001B[0m     ]\n\u001B[0;32m    326\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m boxes_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    327\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 328\u001B[0m         [(augment_box(box), character) \u001B[38;5;28;01mfor\u001B[39;00m box, character \u001B[38;5;129;01min\u001B[39;00m line] \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m boxes\n\u001B[0;32m    329\u001B[0m     ]\n\u001B[0;32m    330\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    331\u001B[0m         [\n\u001B[0;32m    332\u001B[0m             (box, character)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    338\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m boxes_augmented\n\u001B[0;32m    339\u001B[0m     ]\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;66;03m# Sometimes all the characters in a line are removed.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\image_ocr\\tools.py:328\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    319\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    320\u001B[0m         box\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m inside, box \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    324\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m inside\n\u001B[0;32m    325\u001B[0m     ]\n\u001B[0;32m    326\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m boxes_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    327\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 328\u001B[0m         [(augment_box(box), character) \u001B[38;5;28;01mfor\u001B[39;00m box, character \u001B[38;5;129;01min\u001B[39;00m line] \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m boxes\n\u001B[0;32m    329\u001B[0m     ]\n\u001B[0;32m    330\u001B[0m     boxes_augmented \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    331\u001B[0m         [\n\u001B[0;32m    332\u001B[0m             (box, character)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    338\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m boxes_augmented\n\u001B[0;32m    339\u001B[0m     ]\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;66;03m# Sometimes all the characters in a line are removed.\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7ba846cde077b4aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T14:49:31.837658Z",
     "start_time": "2024-12-05T14:49:31.807754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ],
   "id": "beb8af7ed183bc44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b795217a63bf23a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
